---
title: Pre-processing of *Caenorhabditis* spp. bulk RNA-seq for inclusion in *Caenorhabditis* RNA-Seq Browser
author: "Astra S. Bryant, PhD; Damia Akimori; LaDeana Hilllier"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document: 
    toc: yes
    theme: flatly
    df_print: paged
    code_folding: hide
    toc_depth: 3
    toc_float: true
    number_sections: true
---

# Introduction
The goal of this file is to arrange gene-centric *Caenorhbaditis* RNA-seq data originally published as part of the modENCODE project or by the Waterston Lab at the University of Washington ([Gerstein *et al* 2010](https://pubmed.ncbi.nlm.nih.gov/21177976/), [Gerstein *et al* 2014](https://www.nature.com/articles/nature13424), and [Warner *et al* 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6581053/)).  

## Update Notes  


# Pre-processing Methods Overview  
Each genome and gff file were downloaded from WormBase.org version WS290. Reads were aligned to each genome using STAR (v2.7.6a, --alignIntronMax 30000 --alignMatesGapMax 30000) and the species-specific WS290 GTF file for each genome. PCR duplicates were removed using "seldup" ([Warner et al., 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6581053/)).  Read counts were obtained for each gene (CDS region only which is labeled as "CDS"  in *C. briggsae* and *C. elegans* and as "coding_exon" for *C. remanei*, *C. japonica*, and *C. brenneri*) using featureCounts (from the software package subread-2.0.6) using default settings. Only uniquely mapping reads were counted.  Additionally read counts were obtained for the CDS regions and for the full transcripts using the featureCount options -M --fraction so that multimappers were counted by splitting them equally among all of the locations where they aligned. Alignment and counting was performed by LaDeana Hillier (Waterston Lab, UW). 

Read data for each species was imported into R and annotated with information from WormBase ParaSite BiomaRT.

Raw reads were quantified as counts per million using the EdgeR package, then filtered to remove transcripts with low counts (less than 1 count-per-million). A list of discarded genes and their expression values across life stages was saved. Non-discarded gene values were normalized using the trimmed mean of M-values method (TMM, [Robinson and Oshlack](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-3-r25) ) to permit between-samples comparisons. The mean-variance relationship was modeled using a precision weights approach [Law *et al* 2014](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29).  

This document saves multiple files that are passed to a Shiny Web App for downstream browsing and on-demand analysis. Note that these files are saved in an Outputs folder; in order to make them accessible to a local version of the Shiny browser they need to be moved to appropriate subfolders within the App folder - the www sub folder (for .csv files) or the Data subfolder (for R objects). Stable copies are already located within those folders and do not need to be replaced unless the pre-processing steps change.   

```{r , echo = FALSE,}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	collapse = TRUE
)
```

```{r setup, echo = FALSE, results = FALSE, include = FALSE}
if (!require("BiocManager", quietly = TRUE)) install.packages("BiocManager")
if (!require("tximport", quietly = TRUE)) BiocManager::install("tximport", ask = FALSE)
if (!require("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load("tidyverse","data.table", "magrittr","edgeR","matrixStats","cowplot","ggthemes","gprofiler2","limma","tximport", "knitr")

# Check for presence of output folder, generate if it doesn't exist
output.path <- "./Outputs"
if (!dir.exists(output.path)){
  dir.create(output.path)
}

app.path <-"../Data"
www.path <-"../www"
```

# Code 
Note: Code chunks are collated and echoed at the end of the document in Appendix I.

## Import data into R and generate a Digital Gene Expression List 
Generate a digital gene expression list that could be easily shared/loaded for downstream filtering/normalization.  
```{r txImport, eval=F}
species_list <- tibble(species = c('elegans', 'briggsae', 'brenneri', 'remanei', 'japonica', 'cele_embryonic'))

for (x in species_list$species) {
# read in the study design ----
targets <- read_tsv(paste0("./Data/", x, "/", x,"_study_design.txt"),
                    na = c("", "NA", "na"), show_col_types = F)

# load pre-generated annotation information
load(paste0("./Outputs/",x,"_geneAnnotations"))

# import featureCount output into R ----
if (x == 'elegans' | x == 'briggsae') {
  path <- paste0("./Data/", x, "/featureCount.C_", x,".", targets$Biological_ID, ".CDS.unique_only.ws290.txt")
} else if (x == 'cele_embryonic') {
   path <- paste0("./Data/", x, "/featureCount.C_elegans.", targets$Biological_ID, ".CDS.unique_only.ws290.txt")
} else {
  path <- paste0("./Data/", x, "/featureCount.C_", x,".", targets$Biological_ID, ".coding_exon.unique_only.ws290.txt")
}

featureCountData<- rbindlist(lapply(path, fread), idcol="sample") %>%
mutate(sample = targets$sample[sample])
colnames(featureCountData)<-c('sample','geneID', 'Ce_ortholog', 'stableID', "location", "length", "count")

featureCountData_wider <- featureCountData %>%
  dplyr::select(!c(Ce_ortholog, location, length)) %>%
  pivot_wider(names_from = sample, values_from = count)

counts <- featureCountData_wider %>%
  dplyr::select(-stableID)%>%
  column_to_rownames(var = "geneID")

annotations_sub<-dplyr::select(featureCountData_wider, geneID) %>%
  left_join(annotations, by = "geneID") 

# generate a DGEList
myDGEList <- DGEList(counts,
                     samples = targets$sample,
                     group = targets$group, 
                     genes = annotations_sub)

output.name <- paste0(x, '_DGEList')
save(myDGEList,
     file = file.path(output.path,
                      output.name))
}
```


## Data Filtering, Normalization, and Variance Stabilization
The goal of this chunk is to:

  1. Filter and normalize data. 
  2. Use `ggplot2` to visualize the impact of filtering and normalization on the data (see Output section, below). 
  3. ses a DGEList of filtered and normalized abundance data. It will fit data to a linear model for responsively detecting differentially expressed genes (DGEs).  
  4. Save the following files and datasets:   
    i) filtered and normalized (but not voom adjusted) log2CPM values.  
    ii) a matrix of discarded genes and their raw counts - this data is downloadable from within the Shiny Browser App. 
    iii)  the variance-stabilized vDGEList, saved as an R object (`_vDGEList`). 
    iv) a matrix of variance-stabilized gene expression data, extracted from the vDGEList (`_log2cpm_filtered_norm_voom.csv`) - this data is downloadable from within the Browser App.  
  
```{r dataWrangling, eval=F, echo = TRUE}
species_list <- tibble(species = c('elegans', 'briggsae', 'brenneri', 'remanei', 'japonica', 'cele_embryonic'))
for (x in species_list$species) {
# load pre-generated DGEList information
load(paste0("./Outputs/",x,"_DGEList"))

# load pre-generated annotation information
load(paste0("./Outputs/",x,"_geneAnnotations"))  
  
# read in the study design ----
targets <- read_tsv(paste0("./Data/", x, "/", x,"_study_design.txt"),
                    na = c("", "NA", "na"), show_col_types = F)
# Generate life stage IDs
ids <- rep(cbind(targets$group), 
           times = nrow(myDGEList$counts)) %>%
  as_factor()

# calculate and plot log2 counts per million ----
# use the 'cpm' function from EdgeR to get log2 counts per million
# then coerce into a tibble
log2.cpm.df.pivot <-cpm(myDGEList, log=TRUE) %>%
  as_tibble(rownames = "geneID") %>%
  setNames(nm = c("geneID", targets$sample)) %>%
  pivot_longer(cols = -geneID, 
               names_to = "samples", 
               values_to = "expression") %>% 
  add_column(life_stage = ids)

# plot the data
p1 <- ggplot(log2.cpm.df.pivot) +
  aes(x=samples, y=expression, fill=life_stage) +
  geom_violin(trim = FALSE, show.legend = T, alpha= 0.7) +
  stat_summary(fun = "median", 
               geom = "point", 
               shape = 20, 
               size = 2, 
               color = "black", 
               show.legend = FALSE) +
  labs(y="log2 expression", x = "sample",
       title = paste0("C. ", x, ": Log2 Counts per Million (CPM)"),
       subtitle="unfiltered, non-normalized",
       caption=paste0("produced on ", Sys.time())) +
  theme_bw() +
  coord_flip()
# Filter the data ----

# filter genes/transcripts with low counts
# how many genes had more than 1 CPM (TRUE) in at least n samples
# Note: The cutoff "n" is adjusted for the number of 
# samples in the smallest group of comparison.
keepers <- cpm(myDGEList) %>%
  rowSums(.>1)>=1

myDGEList.filtered <- myDGEList[keepers,]

ids.filtered <- rep(cbind(targets$group), 
                    times = nrow(myDGEList.filtered)) %>%
  as_factor()

log2.cpm.filtered.df.pivot <- cpm(myDGEList.filtered, log=TRUE) %>%
  as_tibble(rownames = "geneID") %>%
  setNames(nm = c("geneID", targets$sample)) %>%
  pivot_longer(cols = -geneID,
               names_to = "samples",
               values_to = "expression") %>%
  add_column(life_stage = ids.filtered)

p2 <- ggplot(log2.cpm.filtered.df.pivot) +
  aes(x=samples, y=expression, fill=life_stage) +
  geom_violin(trim = FALSE, show.legend = T, alpha= 0.7) +
  stat_summary(fun = "median", 
               geom = "point", 
               shape = 20, 
               size = 2, 
               color = "black", 
               show.legend = FALSE) +
  labs(y="log2 expression", x = "sample",
       title = paste0("C. ", x, ": Log2 Counts per Million (CPM)"),
       subtitle="filtered, non-normalized",
       caption=paste0("produced on ", Sys.time())) +
  theme_bw() +
  coord_flip()

# Look at the genes excluded by the filtering step ----
# just to check that there aren't any with 
# high expression that are in few samples
# Discarded genes
myDGEList.discarded <- myDGEList[!keepers,]

ids.discarded <- rep(cbind(targets$group), 
                     times = nrow(myDGEList.discarded)) %>%
  as_factor()

log2.cpm.discarded.df.pivot <- cpm(myDGEList.discarded, log=F) %>%
  as_tibble(rownames = "geneID") %>%
  setNames(nm = c("geneID", targets$sample)) %>%
  pivot_longer(cols = -geneID,
               names_to = "samples",
               values_to = "expression") %>%
  add_column(life_stage = ids.discarded)

# Genes that are above 1 cpm
log2.cpm.discarded.df.pivot %>%
  dplyr::filter(expression > 1)

# Generate a matrix of discarded genes and their raw counts ----
discarded.gene.df <- log2.cpm.discarded.df.pivot %>%
  pivot_wider(names_from = c(life_stage, samples), 
              names_sep = "-", 
              values_from = expression, 
              id_cols = geneID)%>%
  left_join(annotations, by = "geneID") 

# Save a matrix of discarded genes and their raw counts ----
output.name <- paste0(x, '_discardedGenes.csv')

discarded.gene.df %>%    
write.csv(file = file.path(output.path,
                           output.name))

# Plot discarded genes
p.discarded <- ggplot(log2.cpm.discarded.df.pivot) +
  aes(x=samples, y=expression, color=life_stage) +
  geom_jitter(alpha = 0.3, show.legend = T)+
  stat_summary(fun = "median", 
               geom = "point", 
               shape = 20, 
               size = 2, 
               color = "black", 
               show.legend = FALSE) +
  labs(y="expression", x = "sample",
       title = paste0("C. ", x, ": Counts per Million (CPM)"),
       subtitle="genes excluded by low count filtering step, non-normalized",
       caption=paste0("produced on ", Sys.time())) +
  theme_bw() +
  coord_flip()
  
# Normalize the data using a between samples normalization ----
# Source for TMM sample normalization here:
# https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-3-r25
myDGEList.filtered.norm <- calcNormFactors(myDGEList.filtered, method = "TMM")

log2.cpm.filtered.norm <- cpm(myDGEList.filtered.norm, log=TRUE) 

log2.cpm.filtered.norm.df<- cpm(myDGEList.filtered.norm, log=TRUE) %>%
  as_tibble(rownames = "geneID") %>%
  setNames(nm = c("geneID", targets$sample))

log2.cpm.filtered.norm.df.pivot<-log2.cpm.filtered.norm.df %>%
  pivot_longer(cols = -geneID,
               names_to = "samples",
               values_to = "expression") %>%
  add_column(life_stage = ids.filtered)

p3 <- ggplot(log2.cpm.filtered.norm.df.pivot) +
  aes(x=samples, y=expression, fill=life_stage) +
  geom_violin(trim = FALSE, show.legend = T, alpha = 0.7) +
  stat_summary(fun = "median", 
               geom = "point", 
               shape = 20, 
               size = 2, 
               color = "black", 
               show.legend = FALSE) +
  labs(y="log2 expression", x = "sample",
       title = paste0("C. ", x, ": Log2 Counts per Million (CPM)"),
       subtitle="filtered, TMM normalized",
       caption=paste0("produced on ", Sys.time())) +
  theme_bw() +
  coord_flip()

output.name <- paste0(x, '_FilteringNormalizationGraphs')
save(p1, p2, p3, p.discarded, discarded.gene.df,
     file = file.path(output.path,
                      output.name))

output.name <- paste0(x, '_DGEList_filtered_normalized')
save(myDGEList.filtered.norm,
     file = file.path(output.path,
                      output.name))


# Compute Variance-Stabilized DGEList Object ----

# Set up the design matrix ----
# no intercept/blocking for matrix, comparisons across group
group <- factor(targets$group)
design <- model.matrix(~0 + group) 
colnames(design) <- levels(group)

# NOTE: To handle a 'blocking' design' or a batch effect, use:
# design <- model.matrix(~block + treatment)

# Model mean-variance trend and fit linear model to data ----
# Use VOOM function from Limma package to model the mean-variance relationship
# produces a variance-stabilized DGEList, that include precision 
# weights for each gene to try and control for heteroscedasity.
# transforms count data to log2-counts per million
# Outputs: E = normalized expression values on the log2 scale
v.DGEList.filtered.norm <- voom(counts = myDGEList.filtered.norm, 
                                design = design, plot = T)
colnames(v.DGEList.filtered.norm)<-targets$sample
colnames(v.DGEList.filtered.norm$E) <- paste(targets$group, 
                                             targets$sample,sep = '-')


# Save matrix of genes and their filtered, normalized, voom-transformed counts ----
# This is the count data that underlies the differential expression analyses in the Shiny app. 
# Saving it here so that users of the app can access the input information.
output.name <- paste0(x, '_log2cpm_filtered_norm_voom.csv')

# Save in Shiny app download (www) folder
write.csv(v.DGEList.filtered.norm$E, 
          file = file.path(www.path,
                           output.name))
# Save v.DGEList ----
# Save in Shiny app Data folder
output.name <- paste0(x, '_vDGEList')
save(v.DGEList.filtered.norm,
     file = file.path(app.path,
                      output.name))

}
```

# Filtering and Normalization Results

## *C. elegans* Filtering Results {.tabset}

### Unfiltered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
load(paste0("./Outputs/elegans_FilteringNormalizationGraphs"))
p1
```

### Filtered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
p2
```

### Filtered, normalized log2CPM data by life stage
```{r, echo = FALSE, include = TRUE}
p3
```

### Genes discarded by low-copy filtering step  
```{r, echo = FALSE, include = TRUE}
p.discarded
```

### Discarded gene list 
```{r, echo = FALSE, include = TRUE, results = 'asis'}

DT::datatable(discarded.gene.df,
              rownames = FALSE,
                      escape = FALSE,
                      options = list(autoWidth = TRUE,
                                     scrollX = TRUE,
                                     scrollY = '300px',
                                     scrollCollapse = TRUE,
                                     
                                     searchHighlight = TRUE, 
                                     pageLength = 10, 
                                     lengthMenu = c("5",
                                                    "10",
                                                    "25",
                                                    "50",
                                                    "100"),
                                     initComplete = htmlwidgets::JS(
                                         "function(settings, json) {",
                                         paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
                                         "}")  
                      )) %>%
  DT::formatRound(columns=c(2:(ncol(discarded.gene.df)-10)), 
                        digits=3)
```

## *C. briggsae* Filtering Results {.tabset}
### Unfiltered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
rm("p1", "p2", "p3", "p.discarded", "discarded.gene.df")
load(paste0("./Outputs/briggsae_FilteringNormalizationGraphs"))
p1
```

### Filtered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
p2
```

### Filtered, normalized log2CPM data by life stage
```{r, echo = FALSE, include = TRUE}
p3
```

### Genes discarded by low-copy filtering step  
```{r, echo = FALSE, include = TRUE}
p.discarded
```

### Discarded gene list 
```{r, echo = FALSE, include = TRUE, results = 'asis'}

DT::datatable(discarded.gene.df,
              rownames = FALSE,
                      escape = FALSE,
                      options = list(autoWidth = TRUE,
                                     scrollX = TRUE,
                                     scrollY = '300px',
                                     scrollCollapse = TRUE,
                                     
                                     searchHighlight = TRUE, 
                                     pageLength = 10, 
                                     lengthMenu = c("5",
                                                    "10",
                                                    "25",
                                                    "50",
                                                    "100"),
                                     initComplete = htmlwidgets::JS(
                                         "function(settings, json) {",
                                         paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
                                         "}")  
                      )) %>%
  DT::formatRound(columns=c(2:(ncol(discarded.gene.df)-10)), 
                        digits=3)
```

## *C. brenneri* Filtering Results {.tabset}
### Unfiltered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
rm("p1", "p2", "p3", "p.discarded", "discarded.gene.df")
load(paste0("./Outputs/brenneri_FilteringNormalizationGraphs"))
p1
```

### Filtered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
p2
```

### Filtered, normalized log2CPM data by life stage
```{r, echo = FALSE, include = TRUE}
p3
```

### Genes discarded by low-copy filtering step  
```{r, echo = FALSE, include = TRUE}
p.discarded
```

### Discarded gene list 
```{r, echo = FALSE, include = TRUE, results = 'asis'}

DT::datatable(discarded.gene.df,
              rownames = FALSE,
                      escape = FALSE,
                      options = list(autoWidth = TRUE,
                                     scrollX = TRUE,
                                     scrollY = '300px',
                                     scrollCollapse = TRUE,
                                     
                                     searchHighlight = TRUE, 
                                     pageLength = 10, 
                                     lengthMenu = c("5",
                                                    "10",
                                                    "25",
                                                    "50",
                                                    "100"),
                                     initComplete = htmlwidgets::JS(
                                         "function(settings, json) {",
                                         paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
                                         "}")  
                      )) %>%
  DT::formatRound(columns=c(2:(ncol(discarded.gene.df)-10)), 
                        digits=3)
```

## *C. remanei* Filtering Results {.tabset}
### Unfiltered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
rm("p1", "p2", "p3", "p.discarded", "discarded.gene.df")
load(paste0("./Outputs/remanei_FilteringNormalizationGraphs"))
p1
```

### Filtered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
p2
```

### Filtered, normalized log2CPM data by life stage
```{r, echo = FALSE, include = TRUE}
p3
```

### Genes discarded by low-copy filtering step  
```{r, echo = FALSE, include = TRUE}
p.discarded
```

### Discarded gene list 
```{r, echo = FALSE, include = TRUE, results = 'asis'}

DT::datatable(discarded.gene.df,
              rownames = FALSE,
                      escape = FALSE,
                      options = list(autoWidth = TRUE,
                                     scrollX = TRUE,
                                     scrollY = '300px',
                                     scrollCollapse = TRUE,
                                     
                                     searchHighlight = TRUE, 
                                     pageLength = 10, 
                                     lengthMenu = c("5",
                                                    "10",
                                                    "25",
                                                    "50",
                                                    "100"),
                                     initComplete = htmlwidgets::JS(
                                         "function(settings, json) {",
                                         paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
                                         "}")  
                      )) %>%
  DT::formatRound(columns=c(2:(ncol(discarded.gene.df)-10)), 
                        digits=3)
```


## *C. japonica* Filtering Results {.tabset}
### Unfiltered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
rm("p1", "p2", "p3", "p.discarded", "discarded.gene.df")
load(paste0("./Outputs/japonica_FilteringNormalizationGraphs"))
p1
```

### Filtered, non-normalized log2CPM data
```{r, echo = FALSE, include = TRUE}
p2
```

### Filtered, normalized log2CPM data by life stage
```{r, echo = FALSE, include = TRUE}
p3
```

### Genes discarded by low-copy filtering step  
```{r, echo = FALSE, include = TRUE}
p.discarded
```

### Discarded gene list 
```{r, echo = FALSE, include = TRUE, results = 'asis'}

DT::datatable(discarded.gene.df,
              rownames = FALSE,
                      escape = FALSE,
                      options = list(autoWidth = TRUE,
                                     scrollX = TRUE,
                                     scrollY = '300px',
                                     scrollCollapse = TRUE,
                                     
                                     searchHighlight = TRUE, 
                                     pageLength = 10, 
                                     lengthMenu = c("5",
                                                    "10",
                                                    "25",
                                                    "50",
                                                    "100"),
                                     initComplete = htmlwidgets::JS(
                                         "function(settings, json) {",
                                         paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
                                         "}")  
                      )) %>%
  DT::formatRound(columns=c(2:(ncol(discarded.gene.df)-10)), 
                        digits=3)
```



# Appendix I : All code for this report  
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE, include = TRUE}
```

# Appendix II: Session Info
```{r sessionInfo, message = TRUE, 	include = TRUE}
sessionInfo()
```
